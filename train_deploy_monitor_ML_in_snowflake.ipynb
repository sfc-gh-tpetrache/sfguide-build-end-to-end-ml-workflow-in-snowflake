{
 "metadata": {
  "kernelspec": {
   "display_name": "Python37 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "lastEditStatus": {
   "notebookId": "dxjqromavmx5rcxnouo5",
   "authorId": "47704059113",
   "authorName": "ADMIN",
   "authorEmail": "tatiana.petrache@snowflake.com",
   "sessionId": "9fdf5cc5-f840-4b9b-83d8-bad83ba34f3e",
   "lastEditTime": 1765719553753
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79ae8e5-aec2-4276-9443-074c3a614142",
   "metadata": {
    "collapsed": false,
    "name": "INTRO_MD"
   },
   "source": [
    "# ❄️ End-to-end ML Demo ❄️\n",
    "\n",
    "In this worfklow we will work through the following elements of a typical tabular machine learning pipeline.\n",
    "\n",
    "### 1. Use Feature Store to track engineered features\n",
    "* Store feature defintions in feature store for reproducible computation of ML features\n",
    "      \n",
    "### 2. Train two Models using the Snowflake ML APIs\n",
    "* Baseline XGboost\n",
    "* XGboost with optimal hyper-parameters identified via Snowflake ML distributed HPO methods\n",
    "\n",
    "### 3. Register both models in Snowflake model registry\n",
    "* Explore model registry capabilities such as **metadata tracking, inference, and explainability**\n",
    "* Compare model metrics on train/test set to identify any issues of model performance or overfitting\n",
    "* Tag the best performing model version as 'default' version\n",
    "### 4. Set up Model Monitor to track 1 year of predicted and actual loan repayments\n",
    "* **Compute performance metrics** such a F1, Precision, Recall\n",
    "* **Inspect model drift** (i.e. how much has the average predicted repayment rate changed day-to-day)\n",
    "* **Compare models** side-by-side to understand which model should be used in production\n",
    "* Identify and understand **data issues**\n",
    "\n",
    "### 5. Track data and model lineage throughout\n",
    "* View and understand\n",
    "  * The **origin of the data** used for computed features\n",
    "  * The **data used** for model training\n",
    "  * The **available model versions** being monitored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2512cb5-15ae-40b2-84c7-8a44a9979670",
   "metadata": {
    "language": "python",
    "name": "pip_installs",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "!pip install shap snowflake-ml-python==1.19.0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78265b8-8baa-4136-a32a-32f3f620949d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "set_version_num_and_vars"
   },
   "outputs": [],
   "source": "#Update this VERSION_NUM to version your features, models etc!\nVERSION_NUM = '0'\nDB = \"E2E_SNOW_MLOPS_DB\" \nSCHEMA = \"MLOPS_SCHEMA\" \nCOMPUTE_WAREHOUSE = \"E2E_SNOW_MLOPS_WH\" "
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "imports_and_session",
    "resultHeight": 84
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport sklearn\nimport math\nimport pickle\nimport shap\nfrom datetime import datetime\nimport streamlit as st\nfrom xgboost import XGBClassifier\n\n# Snowpark ML\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.modeling.tune import get_tuner_context\nfrom snowflake.ml.modeling import tune\nfrom entities import search_algorithm\n\n#Snowflake feature store\nfrom snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n\n# Snowpark session\nfrom snowflake.snowpark import DataFrame\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark.functions import col, to_timestamp, min, max, month, dayofweek, dayofyear, avg, date_add, make_interval\nfrom snowflake.snowpark.types import IntegerType, DecimalType\nfrom snowflake.snowpark import Window\n\n#setup snowpark session\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n# session.use_role('')\nsession"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8900d1d-a1f2-419b-ae7e-b194f268d904",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "read_raw_data",
    "resultHeight": 223
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Reading table data...\")\n",
    "    df = session.table(\"MORTGAGE_LENDING_DEMO_DATA\")\n",
    "    df.show(5)\n",
    "except:\n",
    "    print(\"Table not found! Uploading data to snowflake table\")\n",
    "    df_pandas = pd.read_csv(\"MORTGAGE_LENDING_DEMO_DATA.csv.zip\")\n",
    "    session.write_pandas(df_pandas, \"MORTGAGE_LENDING_DEMO_DATA\", auto_create_table=True)\n",
    "    df = session.table(\"MORTGAGE_LENDING_DEMO_DATA\")\n",
    "    df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60938b6f-bda7-4783-ae44-547bd34d98de",
   "metadata": {
    "collapsed": false,
    "name": "md1"
   },
   "source": [
    "## Observe Snowflake Snowpark table properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6654de7-6407-4ffe-a214-fd66078397ef",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "see_timespan",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "df.select(min('TS'), max('TS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a38cc-c479-4839-b0ae-9e5cb3e0facb",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "find_timedelta"
   },
   "outputs": [],
   "source": "#Get current date and time\ncurrent_time = datetime.now()\ndf_max_time = datetime.strptime(str(df.select(max(\"TS\")).collect()[0][0]), \"%Y-%m-%d %H:%M:%S.%f\")\n\n#Find delta between latest existing timestamp and today's date\ntimedelta = current_time- df_max_time\n\n#Update timestamps to represent last ~1 year from today's date\ndf.select(min(date_add(to_timestamp(\"TS\"), timedelta.days-1)), max(date_add(to_timestamp(\"TS\"), timedelta.days-1)))\n"
  },
  {
   "cell_type": "markdown",
   "id": "8aa46c7d-519b-422c-8932-9b031fc6b4bd",
   "metadata": {
    "collapsed": false,
    "name": "feat_eng_md"
   },
   "source": [
    "## Feature Engineering with Snowpark APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355c0c4-9dc6-4faf-86b7-24d8d559e453",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_features",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "#Create a dict with keys for feature names and values containing transform code\n\nfeature_eng_dict = dict()\n\n#Timstamp features\nfeature_eng_dict[\"TIMESTAMP\"] = date_add(to_timestamp(\"TS\"), timedelta.days-1)\nfeature_eng_dict[\"MONTH\"] = month(\"TIMESTAMP\")\nfeature_eng_dict[\"DAY_OF_YEAR\"] = dayofyear(\"TIMESTAMP\") \nfeature_eng_dict[\"DOTW\"] = dayofweek(\"TIMESTAMP\")\n\n# df= df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\n\n#Income and loan features\nfeature_eng_dict[\"LOAN_AMOUNT\"] = (col(\"LOAN_AMOUNT_000s\")*1000).cast(DecimalType(15, 2))\nfeature_eng_dict[\"INCOME\"] = (col(\"APPLICANT_INCOME_000s\")*1000).cast(DecimalType(15, 2))\nfeature_eng_dict[\"INCOME_LOAN_RATIO\"] = F.round(col(\"INCOME\")/col(\"LOAN_AMOUNT\"), 4).cast(DecimalType(10, 4))\n\n\ncounty_window_spec = Window.partition_by(\"COUNTY_NAME\")\nfeature_eng_dict[\"MEAN_COUNTY_INCOME\"] = F.round(avg(\"INCOME\").over(county_window_spec), 2).cast(DecimalType(15, 2))\n\nfeature_eng_dict[\"HIGH_INCOME_FLAG\"] = (col(\"INCOME\")>col(\"MEAN_COUNTY_INCOME\")).astype(IntegerType())\n\nfeature_eng_dict[\"AVG_THIRTY_DAY_LOAN_AMOUNT\"] = F.round(\n    F.avg(\"LOAN_AMOUNT\").over(\n        Window.partition_by(\"COUNTY_NAME\")\n        .order_by(\"TIMESTAMP\")\n        .range_between(-make_interval(days=30), 0)  # 30 days preceding to current row\n    ), 2\n).cast(DecimalType(15, 2))\n\ndf = df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4ead8-25ac-46cc-9bd9-17eac2f796d5",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "df_explain",
    "resultHeight": 312
   },
   "outputs": [],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7645e-e0ac-4539-b132-54ce53431402",
   "metadata": {
    "collapsed": false,
    "name": "feature_store_markdown"
   },
   "source": [
    "## Create a Snowflake Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacdc71-9f2c-419f-8d50-3e8f89be367f",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_feature_store",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=DB, \n",
    "    name=SCHEMA, \n",
    "    default_warehouse=COMPUTE_WAREHOUSE,\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67480d6a-183f-4373-aaa8-d3ed8e80e11d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "list_entities",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "fs.list_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915406f-e52d-4baf-9f6c-b9e0e8d53e6e",
   "metadata": {
    "collapsed": false,
    "name": "FS_CONFIG_MD"
   },
   "source": [
    "## Feature Store configuration\n",
    "- create/register entities of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d6d39-7819-4825-8729-a3f19ca5cdf7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "load_or_register_entity",
    "resultHeight": 38
   },
   "outputs": [],
   "source": [
    "#First try to retrieve an existing entity definition, if not define a new one and register\n",
    "try:\n",
    "    #retrieve existing entity\n",
    "    loan_id_entity = fs.get_entity('LOAN_ENTITY') \n",
    "    print('Retrieved existing entity')\n",
    "except:\n",
    "#define new entity\n",
    "    loan_id_entity = Entity(\n",
    "        name = \"LOAN_ENTITY\",\n",
    "        join_keys = [\"LOAN_ID\"],\n",
    "        desc = \"Features defined on a per loan level\")\n",
    "    #register\n",
    "    fs.register_entity(loan_id_entity)\n",
    "    print(\"Registered new entity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820463f-0ea7-43ea-a500-9b034011887d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_feature_df",
    "resultHeight": 217
   },
   "outputs": [],
   "source": [
    "#Create a dataframe with just the ID, timestamp, and engineered features. We will use this to define our feature view\n",
    "feature_df = df.select([\"LOAN_ID\"]+list(feature_eng_dict.keys()))\n",
    "feature_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf84fe3-4120-4092-b43d-8873da57d461",
   "metadata": {
    "collapsed": false,
    "name": "FS_MD"
   },
   "source": [
    "Here, the feature store references an existing table. \n",
    "\n",
    "We could also define the dataframe via the use of Snowpark APIs, and use that dataframe (or a function that returns a dataframe) as the feature view definition, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53364f-90c4-45b4-94ee-b2fde6f93475",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "feature_veiw_creation",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "#define and register feature view\n",
    "loan_fv = FeatureView(\n",
    "    name=\"Mortgage_Feature_View\",\n",
    "    entities=[loan_id_entity],\n",
    "    feature_df=feature_df,\n",
    "    timestamp_col=\"TIMESTAMP\",\n",
    "    refresh_freq=\"1 day\")\n",
    "\n",
    "#add feature level descriptions\n",
    "\n",
    "loan_fv = loan_fv.attach_feature_desc(\n",
    "    {\n",
    "        \"MONTH\": \"Month of loan\",\n",
    "        \"DAY_OF_YEAR\": \"Day of calendar year of loan\",\n",
    "        \"DOTW\": \"Day of the week of loan\",\n",
    "        \"LOAN_AMOUNT\": \"Loan amount in $USD\",\n",
    "        \"INCOME\": \"Household income in $USD\",\n",
    "        \"INCOME_LOAN_RATIO\": \"Ratio of LOAN_AMOUNT/INCOME\",\n",
    "        \"MEAN_COUNTY_INCOME\": \"Average household income aggregated at county level\",\n",
    "        \"HIGH_INCOME_FLAG\": \"Binary flag to indicate whether household income is higher than MEAN_COUNTY_INCOME\",\n",
    "        \"AVG_THIRTY_DAY_LOAN_AMOUNT\": \"Rolling 30 day average of LOAN_AMOUNT\"\n",
    "    }\n",
    ")\n",
    "\n",
    "loan_fv = fs.register_feature_view(loan_fv, version=VERSION_NUM, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3225b-b936-4aa7-81f2-27bbaeee1c0f",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_feature_views",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "fs.list_feature_views()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a1aae-0bd2-4aad-b9ed-3347fc56b6ea",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_feature_store_link"
   },
   "outputs": [],
   "source": [
    "#Create link to feature store UI to inspect newly created feature view!\n",
    "org_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\n",
    "account_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\n",
    "\n",
    "st.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/features/database/{DB}/store/{SCHEMA}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ff67f-bb04-40cb-8c14-11b5ebb2917d",
   "metadata": {
    "collapsed": false,
    "name": "FV_MD"
   },
   "source": [
    "## Retrieve a Dataset from the featureview\n",
    "\n",
    "Snowflake Datasets are immutable, file-based objects that exist within your Snowpark session. \n",
    "\n",
    "They can be written to persistent Snowflake objects as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535efc80-e4fc-41c5-98eb-5b5450bcf199",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "generate_dataset",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "ds = fs.generate_dataset(\n",
    "    name=f\"MORTGAGE_DATASET_EXTENDED_FEATURES_{VERSION_NUM}\",\n",
    "    spine_df=df.select(\"LOAN_ID\", \"TIMESTAMP\", \"LOAN_PURPOSE_NAME\",\"MORTGAGERESPONSE\"), #only need the features used to fetch rest of feature view\n",
    "    features=[loan_fv],\n",
    "    spine_timestamp_col=\"TIMESTAMP\",\n",
    "    spine_label_cols=[\"MORTGAGERESPONSE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdaa537-3fb9-476c-9153-3236edfdfcb3",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "convert_dataset_to_snowpark_and_pandas",
    "resultHeight": 239
   },
   "outputs": [],
   "source": [
    "ds_sp = ds.read.to_snowpark_dataframe()\n",
    "ds_sp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e17036-7a69-4915-b025-49c900aeb46b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "one_hot_encoding",
    "resultHeight": 360
   },
   "outputs": [],
   "source": [
    "import snowflake.ml.modeling.preprocessing as snowml\n",
    "from snowflake.snowpark.types import StringType\n",
    "\n",
    "OHE_COLS = ds_sp.select([col.name for col in ds_sp.schema if col.datatype ==StringType()]).columns\n",
    "OHE_POST_COLS = [i+\"_OHE\" for i in OHE_COLS]\n",
    "\n",
    "\n",
    "# Encode categoricals to numeric columns\n",
    "snowml_ohe = snowml.OneHotEncoder(input_cols=OHE_COLS, output_cols = OHE_COLS, drop_input_cols=True)\n",
    "ds_sp_ohe = snowml_ohe.fit(ds_sp).transform(ds_sp)\n",
    "\n",
    "#Rename columns to avoid double nested quotes and white space chars\n",
    "rename_dict = {}\n",
    "for i in ds_sp_ohe.columns:\n",
    "    if '\"' in i:\n",
    "        rename_dict[i] = i.replace('\"','').replace(' ', '_')\n",
    "\n",
    "ds_sp_ohe = ds_sp_ohe.rename(rename_dict)\n",
    "ds_sp_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834f6f3-ce15-405e-8fec-1d1bb5c224a6",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "train_test_split",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "train, test = ds_sp_ohe.random_split(weights=[0.70, 0.30], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff103e-5314-4e95-87ba-d784b1102f36",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "fill_na",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917df7f-e277-4fbb-abf5-1a4433367e3b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "convert_data_to_pandas"
   },
   "outputs": [],
   "source": [
    "train_pd = train.to_pandas()\n",
    "test_pd = test.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c05dc9-2efb-4c5f-995a-486ef926c6c5",
   "metadata": {
    "collapsed": false,
    "name": "model_training_md"
   },
   "source": [
    "## Model Training\n",
    "### Below we will define and fit an xgboost classifier as our baseline model and evaluate the performance\n",
    "##### Note this is all done with OSS frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b5fba-b7a8-47ff-aaf6-076b9e78dcaf",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_model",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "#Define model config\n",
    "xgb_base = XGBClassifier(\n",
    "    max_depth=50,\n",
    "    n_estimators=3,\n",
    "    learning_rate = 0.75,\n",
    "    booster = 'gbtree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f3295-2496-4fd0-ae95-922a78c5b944",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "train_base_model",
    "resultHeight": 1759
   },
   "outputs": [],
   "source": [
    "#Split train data into X, y\n",
    "X_train_pd = train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1) #remove\n",
    "y_train_pd = train_pd.MORTGAGERESPONSE\n",
    "\n",
    "#train model\n",
    "xgb_base.fit(X_train_pd,y_train_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ac861-fcf9-47b2-9c11-ec44ee2367e4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "compute_predictions_and_perf_metrics"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "train_preds_base = xgb_base.predict(X_train_pd) #update this line with correct ata\n",
    "\n",
    "f1_base_train = round(f1_score(y_train_pd, train_preds_base),4)\n",
    "precision_base_train = round(precision_score(y_train_pd, train_preds_base),4)\n",
    "recall_base_train = round(recall_score(y_train_pd, train_preds_base),4)\n",
    "\n",
    "print(f'F1: {f1_base_train} \\nPrecision {precision_base_train} \\nRecall: {recall_base_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93777778-d2ba-42d5-88c4-a90ba18c5006",
   "metadata": {
    "collapsed": false,
    "name": "model_regisry_md",
    "resultHeight": 74
   },
   "source": [
    "# Model Registry\n",
    "\n",
    "- Log models with important metadata\n",
    "- Manage model lifecycles\n",
    "- Serve models from Snowflake runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21678e59-deaf-4c2b-b01e-1c59fe31b10a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_model_registry",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "#Create a snowflake model registry object \n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "# Define model name\n",
    "model_name = f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\"\n",
    "\n",
    "# Create a registry to log the model to\n",
    "model_registry = Registry(session=session, \n",
    "                          database_name=DB, \n",
    "                          schema_name=SCHEMA,\n",
    "                          options={\"enable_monitoring\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41c3ac-49f0-4fd9-a557-9d8eb633f602",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "register_model_version",
    "resultHeight": 229
   },
   "outputs": [],
   "source": [
    "#Log the base model to the model registry (if not already there)\n",
    "base_version_name = 'XGB_BASE'\n",
    "\n",
    "try:\n",
    "    #Check for existing model\n",
    "    mv_base = model_registry.get_model(model_name).version(base_version_name)\n",
    "    print(\"Found existing model version!\")\n",
    "except:\n",
    "    print(\"Logging new model version...\")\n",
    "    #Log model to registry\n",
    "    mv_base = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=xgb_base, \n",
    "        version_name=base_version_name,\n",
    "        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100), #using snowpark df to maintain lineage\n",
    "        comment = f\"\"\"ML model for predicting loan approval likelihood.\n",
    "                    This model was trained using XGBoost classifier.\n",
    "                    Hyperparameters used were:\n",
    "                    max_depth={xgb_base.max_depth}, \n",
    "                    n_estimators={xgb_base.n_estimators}, \n",
    "                    learning_rate = {xgb_base.learning_rate}, \n",
    "                    algorithm = {xgb_base.booster}\n",
    "                    \"\"\",\n",
    "        target_platforms= [\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n",
    "        options= {\"enable_explainability\": True}\n",
    "\n",
    "    )\n",
    "    \n",
    "    #set metrics\n",
    "    mv_base.set_metric(metric_name=\"Train_F1_Score\", value=f1_base_train)\n",
    "    mv_base.set_metric(metric_name=\"Train_Precision_Score\", value=precision_base_train)\n",
    "    mv_base.set_metric(metric_name=\"Train_Recall_score\", value=recall_base_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2ddab-b02a-4e05-8121-4e97e49e0eea",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_prod_tag"
   },
   "outputs": [],
   "source": [
    "#Create tag for PROD model\n",
    "session.sql(\"CREATE OR REPLACE TAG PROD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0054df-0cd9-4e81-98b8-6564be86b4b9",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_PROD_tag"
   },
   "outputs": [],
   "source": [
    "#Apply prod tag \n",
    "m = model_registry.get_model(model_name)\n",
    "m.comment = \"Loan approval prediction models\" #set model level comment\n",
    "m.set_tag(\"PROD\", base_version_name)\n",
    "m.show_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e294e-929d-4399-b2bb-d5d2d1dd043e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_models",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "model_registry.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dfb281-9751-48a1-a76e-43ffffd9d099",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_model_versions",
    "resultHeight": 146
   },
   "outputs": [],
   "source": [
    "model_registry.get_model(model_name).show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af8a1-7a92-455e-b9a1-8f2c699dfdeb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "print_model_version_and_metrics",
    "resultHeight": 239
   },
   "outputs": [],
   "source": [
    "print(mv_base)\n",
    "print(mv_base.show_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecdf05c-b3b5-4755-bdff-fd187ef07f58",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_model_functions",
    "resultHeight": 2133
   },
   "outputs": [],
   "source": [
    "mv_base.show_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf495261-a8a7-46be-b9c8-3f099268d154",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "predict_from_registry",
    "resultHeight": 351
   },
   "outputs": [],
   "source": [
    "reg_preds = mv_base.run(test, function_name = \"predict\").rename(col('\"output_feature_0\"'), \"MORTGAGE_PREDICTION\")\n",
    "reg_preds.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef61447-10e7-4a38-a429-3da3facf9ce7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "compute_test_metrics"
   },
   "outputs": [],
   "source": [
    "#ds_sp_ohe = ds_sp_ohe.rename(col('\"LOAN_PURPOSE_NAME_Home improvement\"'), \"LOAN_PURPOSE_NAME_Home_improvement\")\n",
    "\n",
    "preds_pd = reg_preds.select([\"MORTGAGERESPONSE\", \"MORTGAGE_PREDICTION\"]).to_pandas()\n",
    "f1_base_test = round(f1_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "precision_base_test = round(precision_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "recall_base_test = round(recall_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "\n",
    "#log metrics to model registry model\n",
    "mv_base.set_metric(metric_name=\"Test_F1_Score\", value=f1_base_test)\n",
    "mv_base.set_metric(metric_name=\"Test_Precision_Score\", value=precision_base_test)\n",
    "mv_base.set_metric(metric_name=\"Test_Recall_score\", value=recall_base_test)\n",
    "\n",
    "print(f'F1: {f1_base_test} \\nPrecision {precision_base_test} \\nRecall: {recall_base_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b477885-35ce-486d-9e86-7d0cc9d48454",
   "metadata": {
    "collapsed": false,
    "name": "HPO_MD"
   },
   "source": "## Oh no! Our model's performance seems to have dropped off significantly from training to our test set. \n\n#### This is evidence that our model is overfit - can we fix this with Distributed Hyperparameter Optimization??"
  },
  {
   "cell_type": "markdown",
   "id": "60c8c205-afc2-46de-838d-495ad40d7de3",
   "metadata": {
    "name": "exp_tracking_md",
    "collapsed": false
   },
   "source": "## This is also an excellent opportunity to test out Snowflake's Experiment Tracking Functionality \n\n#### Snowflake Experiment Tracking provides a mechanism for creating experiments and logging runs within Snowflake from any development environment. This capability allows you to log key pieces of information regarding your model training runs such as model parameters and metrics. In the UI, you can deep dive into a particular run or compare multiple runs to find the optimal model.\n\n#### Below we will train multiple models using distributed HPO and log results to the Experiment Tracker!"
  },
  {
   "cell_type": "code",
   "id": "e4d6860a-da49-42bc-aed9-57692eb5c7a2",
   "metadata": {
    "language": "python",
    "name": "define_HPO_with_exp_tracking"
   },
   "outputs": [],
   "source": "from snowflake.ml.data import DataConnector\nfrom snowflake.ml.modeling.tune import get_tuner_context\nfrom snowflake.ml.modeling import tune\nfrom entities import search_algorithm\nimport psutil\nfrom snowflake.ml.experiment.experiment_tracking import ExperimentTracking\nfrom snowflake.ml.runtime_cluster import get_ray_dashboard_url\n\nst.write('Click the link below to view the ray cluster and follow along with your HPO job progress!')\nst.write('https://'+get_ray_dashboard_url())\n\n#Define dataset map\ndataset_map = {\n    \"x_train\": DataConnector.from_dataframe(train.drop(\"MORTGAGERESPONSE\", \"TIMESTAMP\", \"LOAN_ID\")),\n    \"y_train\": DataConnector.from_dataframe(train.select(\"MORTGAGERESPONSE\")),\n    \"x_test\": DataConnector.from_dataframe(test.drop(\"MORTGAGERESPONSE\",\"TIMESTAMP\", \"LOAN_ID\")),\n    \"y_test\": DataConnector.from_dataframe(test.select(\"MORTGAGERESPONSE\"))\n    }\n\n# exp = ExperimentTracking(session=session)\n\n# Define a training function, with any models you choose within it.\ndef train_func():\n\n    local_session = get_active_session()\n    exp = ExperimentTracking(session=local_session)\n    \n    exp.set_experiment(\"E2E_MLOPS_HPO_Experiments\")\n    with exp.start_run():\n        # A context object provided by HPO API to expose data for the current HPO trial\n        \n        tuner_context = get_tuner_context()\n        \n        #Generate params\n        config = tuner_context.get_hyper_params()\n        dm = tuner_context.get_dataset_map()\n    \n        #Log params to experiment tracking\n        exp.log_params(config)\n        \n        #Instantiate mdoel with generated params\n        model = XGBClassifier(**config, random_state=42)\n    \n        X_train_pd = dm[\"x_train\"].to_pandas().sort_index()\n        y_train_pd = dm[\"y_train\"].to_pandas().sort_index()\n        X_test_pd = dm[\"x_test\"].to_pandas().sort_index()\n        y_test_pd = dm[\"y_test\"].to_pandas().sort_index()\n    \n        #Train model, get preds\n        model.fit(X_train_pd,y_train_pd)\n\n        #Run inference on train preds\n        train_preds = model.predict(X_train_pd)\n\n        #Run inference on test preds\n        test_preds = model.predict(X_test_pd)\n        \n        #compute metrics \n        f1_train = f1_score(y_train_pd,train_preds)\n        precision_train = precision_score(y_train_pd,train_preds)\n        recall_train = recall_score(y_train_pd,train_preds)\n\n        f1_test = f1_score(y_test_pd,test_preds)\n        precision_test = precision_score(y_test_pd,test_preds)\n        recall_test = recall_score(y_test_pd,test_preds)\n    \n        metrics_to_log = {\"F1_Train\": f1_train,\n                         \"Precision_Train\": precision_train,\n                         \"Recall_Train\": recall_train,\n                         \"F1_Test\": f1_test,\n                         \"Precision_Test\": precision_test,\n                         \"Recall_Test\": recall_test,}\n    \n        #Log metrics to experiment tracking and tuner context \n        exp.log_metrics(metrics_to_log)\n    \n        tuner_context.report(metrics=metrics_to_log, model=model)\n        \ntuner = tune.Tuner(\n    train_func=train_func,\n    search_space={\n        \"max_depth\": tune.randint(1, 30),\n        \"learning_rate\": tune.uniform(0.01, 0.5),\n        \"n_estimators\": tune.randint(50, 150),\n    },\n    tuner_config=tune.TunerConfig(\n        metric=\"F1_Test\",\n        mode=\"max\",\n        search_alg=search_algorithm.RandomSearch(random_state=101),\n        num_trials=8, #run 8 trial runs\n        max_concurrent_trials=psutil.cpu_count(logical=False) # Use all available CPUs to run distributed HPO across. GPUs can also be used here! \n    ),\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "832807a0-2572-402f-9b7a-1803a3c91c19",
   "metadata": {
    "language": "python",
    "name": "run_hpo_and_inspect_results"
   },
   "outputs": [],
   "source": "tuner_results = tuner.run(dataset_map=dataset_map)\ntuner_results.results",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f707f92-4cfc-43a1-85ad-3097a2c92303",
   "metadata": {
    "language": "python",
    "name": "generate_experiment_tracking_link"
   },
   "outputs": [],
   "source": "#Now access the Experiment Tracking UI to compare performance metrics and hyperparameters across different runs!\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/experiments/databases/{DB}/schemas/{SCHEMA}/experiments/E2E_MLOPS_HPO_EXPERIMENTS')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee37c42-3de7-476a-b7c0-d56952dac385",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "inspect_hpo_params"
   },
   "outputs": [],
   "source": [
    "#Select best model results and inspect configuration\n",
    "tuned_model = tuner_results.best_model\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4a6c2-674e-4d02-afdb-8ebf10cffdc4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "compute_hpo_train_predictions_and_metrics"
   },
   "outputs": [],
   "source": "#Generate predictions\nxgb_opt_preds = tuned_model.predict(train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n\n#Generate performance metrics\nf1_opt_train = round(f1_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\nprecision_opt_train = round(precision_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\nrecall_opt_train = round(recall_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n\nprint(f'Train Results: \\nF1: {f1_opt_train} \\nPrecision {precision_opt_train} \\nRecall: {recall_opt_train}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee80c48-d521-4b77-8841-54ba35ecd4b6",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "compute_hpo_test_predictions_and_metrics"
   },
   "outputs": [],
   "source": [
    "#Generate test predictions\n",
    "xgb_opt_preds_test = tuned_model.predict(test_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n",
    "\n",
    "#Generate performance metrics on test data\n",
    "f1_opt_test = round(f1_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "precision_opt_test = round(precision_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "recall_opt_test = round(recall_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "\n",
    "print(f'Test Results: \\nF1: {f1_opt_test} \\nPrecision {precision_opt_test} \\nRecall: {recall_opt_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1a670-52e3-4d77-ac3a-db830e22fdcf",
   "metadata": {
    "collapsed": false,
    "name": "HPO_performance_reaction"
   },
   "source": "## Here we see the HPO model has a more modest train accuracy than our base model - but the peformance doesn't drop off on new data (test set) "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501cf7d-4965-4b9f-8b16-edab897d0e18",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "log_hpo_model"
   },
   "outputs": [],
   "source": [
    "#Log the optimized model to the model registry (if not already there)\n",
    "optimized_version_name = 'XGB_Optimized'\n",
    "\n",
    "try:\n",
    "    #Check for existing model\n",
    "    mv_opt = model_registry.get_model(model_name).version(optimized_version_name)\n",
    "    print(\"Found existing model version!\")\n",
    "except:\n",
    "    #Log model to registry\n",
    "    print(\"Logging new model version...\")\n",
    "    mv_opt = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=tuned_model, \n",
    "        version_name=optimized_version_name,\n",
    "        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100),\n",
    "        comment = f\"\"\"HPO ML model for predicting loan approval likelihood.\n",
    "            This model was trained using XGBoost classifier.\n",
    "            Optimized hyperparameters used were:\n",
    "            max_depth={tuned_model.max_depth}, \n",
    "            n_estimators={tuned_model.n_estimators}, \n",
    "            learning_rate = {tuned_model.learning_rate}, \n",
    "            \"\"\",\n",
    "        target_platforms= [\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n",
    "        options= {\"enable_explainability\": True}\n",
    "\n",
    "        \n",
    "\n",
    "    )\n",
    "    #Set metrics\n",
    "    mv_opt.set_metric(metric_name=\"Train_F1_Score\", value=f1_opt_train)\n",
    "    mv_opt.set_metric(metric_name=\"Train_Precision_Score\", value=precision_opt_train)\n",
    "    mv_opt.set_metric(metric_name=\"Train_Recall_score\", value=recall_opt_train)\n",
    "\n",
    "    mv_opt.set_metric(metric_name=\"Test_F1_Score\", value=f1_opt_test)\n",
    "    mv_opt.set_metric(metric_name=\"Test_Precision_Score\", value=precision_opt_test)\n",
    "    mv_opt.set_metric(metric_name=\"Test_Recall_score\", value=recall_opt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c028b9-b590-45b4-9884-35ee206bca0d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "inspect_current_default_version"
   },
   "outputs": [],
   "source": [
    "#Here we see the BASE version is our default version\n",
    "model_registry.get_model(model_name).default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac97a9-7af4-4331-bb0d-cf6ecc4a77f6",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "promote_optimized_version_to_default"
   },
   "outputs": [],
   "source": [
    "#Now we'll set the optimized model to be the default model version going forward\n",
    "model_registry.get_model(model_name).default = optimized_version_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04efcee-27e6-4423-b669-849bec7cc8fb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "see_updated_model_versions"
   },
   "outputs": [],
   "source": "#Now we see our optimized version we have now recently promoted to our DEFAULT model version\nmodel_registry.get_model(model_name).default"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc92f7f-5f02-4cc5-82d0-758f65f2d485",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "update_model_tags"
   },
   "outputs": [],
   "source": [
    "#we'll now update the PROD tagged model to be the optimized model version rather than our overfit base version\n",
    "m.unset_tag(\"PROD\")\n",
    "m.set_tag(\"PROD\", optimized_version_name)\n",
    "m.show_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fff15e-5f49-4d4f-a02a-93e8f3114b11",
   "metadata": {
    "collapsed": false,
    "name": "explainability_MD"
   },
   "source": "\n## Now that we've deployed some model versions and tested inference... \n# Let's explain our models!\n- ### Snowflake offers built in explainability capabilities on top of models logged to the model registry\n- ### In the below section we'll generate shapley values using these built in functions to understand how input features impact our model's behavior"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f5cd6-d254-42d4-a0be-9848c9d09d4a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "compute_shap_vals",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "#create a sample of 1000 records\n",
    "test_pd_sample=test_pd.rename(columns=rename_dict).sample(n=2500, random_state = 100).reset_index(drop=True)\n",
    "\n",
    "#Compute shapley values for each model\n",
    "base_shap_pd = mv_base.run(test_pd_sample, function_name=\"explain\")\n",
    "opt_shap_pd = mv_opt.run(test_pd_sample, function_name=\"explain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606c231-2e6a-44ec-a17c-88bb5a3b6494",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "builtin_visualizations"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.monitoring import explain_visualize\n",
    "\n",
    "feat_df=test_pd_sample.drop([\"MORTGAGERESPONSE\",\"TIMESTAMP\", \"LOAN_ID\"],axis=1)\n",
    "\n",
    "explain_visualize.plot_influence_sensitivity(base_shap_pd, feat_df, figsize=(1500, 500))\n",
    "\n",
    "#Optionally test out other built-in functionality \n",
    "# explain_visualize.plot_force(base_shap_pd.iloc[0], feat_df.iloc[0], figsize=(1500, 500))\n",
    "# explain_visualize.plot_violin(base_shap_pd, feat_df, figsize=(1400, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cfb33-1062-487d-83bc-e3d32835e0d9",
   "metadata": {
    "collapsed": false,
    "name": "shap_viz"
   },
   "source": [
    "### In addition to built-in visualization capabilities you can always use open source packages like shap for additional visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e0dcc-a850-474a-b475-f05a77619731",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "base_shap_summary_plot",
    "resultHeight": 571
   },
   "outputs": [],
   "source": [
    "import shap \n",
    "\n",
    "shap.summary_plot(np.array(base_shap_pd.astype(float)), \n",
    "                  test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1), \n",
    "                  feature_names = test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67469a84-3d44-49e4-8d6e-5cd8a6e8a633",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "opt_shap_summary_plot"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(np.array(opt_shap_pd.astype(float)), \n",
    "                  test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1), \n",
    "                  feature_names = test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0d4c3-750c-4ae0-9812-85b677db6986",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_all_shap_dfs"
   },
   "outputs": [],
   "source": [
    "#Merge shap vals and actual vals together for easier plotting below\n",
    "all_shap_base = test_pd_sample.merge(base_shap_pd, right_index=True, left_index=True, how='outer')\n",
    "all_shap_opt = test_pd_sample.merge(opt_shap_pd, right_index=True, left_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938441fd-9ae3-4f97-9a54-b7e4c74738ac",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "plot_income_explanation"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#filter data down to strip outliers\n",
    "asb_filtered = all_shap_base[(all_shap_base.INCOME>0) & (all_shap_base.INCOME<250000)]\n",
    "aso_filtered = all_shap_opt[(all_shap_opt.INCOME>0) & (all_shap_opt.INCOME<250000)]\n",
    "\n",
    "# Set up the figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "fig.suptitle(\"INCOME EXPLANATION\")\n",
    "# Plot side-by-side boxplots\n",
    "sns.scatterplot(data = asb_filtered, x ='INCOME', y = 'INCOME_explanation', ax=axes[0])\n",
    "sns.regplot(data = asb_filtered, x =\"INCOME\", y = 'INCOME_explanation', scatter=False, color='red', line_kws={\"lw\":2},ci =100, lowess=False, ax =axes[0])\n",
    "\n",
    "axes[0].set_title('Base Model')\n",
    "sns.scatterplot(data = aso_filtered, x ='INCOME', y = 'INCOME_explanation',color = \"orange\", ax = axes[1])\n",
    "sns.regplot(data = aso_filtered, x =\"INCOME\", y = 'INCOME_explanation', scatter=False, color='blue', line_kws={\"lw\":2},ci =100, lowess=False, ax =axes[1])\n",
    "axes[1].set_title('Opt Model')\n",
    "\n",
    "# Customize and show the plot\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Income\")\n",
    "    ax.set_ylabel(\"Influence\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298b1f8-0495-42e1-b668-0dcd03d8bb7c",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "plot_loan_amount_explanation"
   },
   "outputs": [],
   "source": [
    "#filter data down to strip outliers\n",
    "asb_filtered = all_shap_base[all_shap_base.LOAN_AMOUNT<2000000]\n",
    "aso_filtered = all_shap_opt[all_shap_opt.LOAN_AMOUNT<2000000]\n",
    "\n",
    "\n",
    "# Set up the figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "fig.suptitle(\"LOAN_AMOUNT EXPLANATION\")\n",
    "# Plot side-by-side boxplots\n",
    "sns.scatterplot(data = asb_filtered, x ='LOAN_AMOUNT', y = 'LOAN_AMOUNT_explanation', ax=axes[0])\n",
    "sns.regplot(data = asb_filtered, x =\"LOAN_AMOUNT\", y = 'LOAN_AMOUNT_explanation', scatter=False, color='red', line_kws={\"lw\":2},ci =100, lowess=True, ax =axes[0])\n",
    "axes[0].set_title('Base Model')\n",
    "\n",
    "sns.scatterplot(data = aso_filtered, x ='LOAN_AMOUNT', y = 'LOAN_AMOUNT_explanation',color = \"orange\", ax = axes[1])\n",
    "sns.regplot(data = aso_filtered, x =\"LOAN_AMOUNT\", y = 'LOAN_AMOUNT_explanation', scatter=False, color='blue', line_kws={\"lw\":2},ci =100, lowess=True, ax =axes[1])\n",
    "axes[1].set_title('Opt Model')\n",
    "\n",
    "# Customize and show the plot\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"LOAN_AMOUNT\")\n",
    "    ax.set_ylabel(\"Influence\")\n",
    "    # ax.set_xlim((0,10000))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a03aa9-1f1a-4a4e-809e-b22e438d72aa",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "plot_home_purchase_explanation",
    "resultHeight": 851
   },
   "outputs": [],
   "source": "# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"HOME PURCHASE LOAN EXPLANATION\")\n# Plot side-by-side boxplots\nsns.boxplot(data = all_shap_base, x ='LOAN_PURPOSE_NAME_HOME_PURCHASE', y = 'LOAN_PURPOSE_NAME_HOME_PURCHASE_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_PURCHASE', width=0.8, ax=axes[0])\naxes[0].set_title('Base Model')\nsns.boxplot(data = all_shap_opt, x ='LOAN_PURPOSE_NAME_HOME_PURCHASE', y = 'LOAN_PURPOSE_NAME_HOME_PURCHASE_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_PURCHASE', width=0.8, ax = axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"Home PURCHASE Loan (1 = True)\")\n    ax.set_ylabel(\"Influence\")\n    ax.legend(loc='upper right')\n\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea7aad-4e48-4666-a48c-ddc39331cb1f",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "plot_home_imrprovement_explanation"
   },
   "outputs": [],
   "source": "# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"HOME IMPROVEMENT LOAN EXPLANATION\")\n# Plot side-by-side boxplots\nsns.boxplot(data = all_shap_base, x ='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', y = 'LOAN_PURPOSE_NAME_HOME_IMPROVEMENT_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', width=0.8, ax=axes[0])\naxes[0].set_title('Base Model')\nsns.boxplot(data = all_shap_opt, x ='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', y = 'LOAN_PURPOSE_NAME_HOME_IMPROVEMENT_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', width=0.8, ax = axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"Home Improvement Loan (1 = True)\")\n    ax.set_ylabel(\"Influence\")\n    ax.legend(loc='upper right')\n\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "df7a9ccc-e785-4a82-b9e9-97fd44d5acf2",
   "metadata": {
    "collapsed": false,
    "name": "Monitoring_section",
    "resultHeight": 74
   },
   "source": [
    "# Model Monitoring setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0751bdd-6c24-4c65-9247-aa90ebc1d376",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_table_from_test_data",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "train.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TRAIN_{VERSION_NUM}\", mode=\"overwrite\")\n",
    "test.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TEST_{VERSION_NUM}\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabdf2be-87f8-4556-aa42-22e4a70515e1",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_stage",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "session.sql(\"CREATE stage IF NOT EXISTS ML_STAGE\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2c090-5cc8-4847-982a-fb9b5e427616",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_sproc",
    "resultHeight": 495
   },
   "outputs": [],
   "source": [
    "from snowflake import snowpark\n",
    "\n",
    "def demo_inference_sproc(session: snowpark.Session, table_name: str, modelname: str, modelversion: str) -> str:\n",
    "\n",
    "    reg = Registry(session=session)\n",
    "    m = reg.get_model(model_name)  # Fetch the model using the registry\n",
    "    mv = m.version(modelversion)\n",
    "    \n",
    "    input_table_name=table_name\n",
    "    pred_col = f'{modelversion}_PREDICTION'\n",
    "\n",
    "    # Read the input table to a dataframe\n",
    "    df = session.table(input_table_name)\n",
    "    results = mv.run(df, function_name=\"predict\").select(\"LOAN_ID\",'\"output_feature_0\"').withColumnRenamed('\"output_feature_0\"', pred_col)\n",
    "    # 'results' is the output DataFrame with predictions\n",
    "\n",
    "    final = df.join(results, on=\"LOAN_ID\", how=\"full\")\n",
    "    # Write results back to Snowflake table\n",
    "    final.write.save_as_table(table_name, mode='overwrite',enable_schema_evolution=True)\n",
    "\n",
    "    return \"Success\"\n",
    "\n",
    "# Register the stored procedure\n",
    "session.sproc.register(\n",
    "    func=demo_inference_sproc,\n",
    "    name=\"model_inference_sproc\",\n",
    "    replace=True,\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@ML_STAGE\",\n",
    "    packages=['joblib', 'snowflake-snowpark-python', 'snowflake-ml-python'],\n",
    "    return_type=StringType()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45031a-917e-4f6d-a2e4-068879791819",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "gb_base_train_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}','{{model_name}}', '{{base_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18ea05-7d29-43a3-9baa-52509f3bb15e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "gb_base_test_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}','{{model_name}}', '{{base_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2550b-46c7-4eb7-adaa-64c345711b1e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "gb_opt_train_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}','{{model_name}}', '{{optimized_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245f482-19e9-4961-9cb2-801bf5948d52",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "gb_opt_test_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}','{{model_name}}', '{{optimized_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05048c-a9d1-4ef9-bf39-5333f3fb56cb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "see_preds",
    "resultHeight": 251
   },
   "outputs": [],
   "source": [
    "select TIMESTAMP, LOAN_ID, INCOME, LOAN_AMOUNT, XGB_BASE_PREDICTION, XGB_OPTIMIZED_PREDICTION, MORTGAGERESPONSE \n",
    "FROM DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}} \n",
    "limit 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c348e-0e6d-4ee3-88c3-59077b409621",
   "metadata": {
    "name": "model_monitor_markdown",
    "collapsed": false
   },
   "source": "## Now that our models have been deployed and we have run inference - lets set up ML Observability!\n\n- First we will add a column to our inference data to later explore with our segemntation capabilities \n- We will define a model monitor for each model, with the training data as our baseline and the test data representing inference results. \n- Once the monitors are defined we can access them via the Model Registry \n    - We can also query drift metrics etc. programmatically"
  },
  {
   "cell_type": "code",
   "id": "a16befd0-410b-4777-bbf6-bfa3580c4973",
   "metadata": {
    "language": "sql",
    "name": "create_segment_col_test"
   },
   "outputs": [],
   "source": "ALTER TABLE DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\nADD COLUMN IF NOT EXISTS LOAN_PURPOSE VARCHAR(50);\n\n\nUPDATE DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\nSET LOAN_PURPOSE = CASE\n    WHEN LOAN_PURPOSE_NAME_HOME_IMPROVEMENT = 1 THEN 'HOME_IMPROVEMENT'\n    WHEN LOAN_PURPOSE_NAME_HOME_PURCHASE = 1 THEN 'HOME_PURCHASE'\n    WHEN LOAN_PURPOSE_NAME_REFINANCING = 1 THEN 'REFINANCING'\n    ELSE 'OTHER'\nEND;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f5a191e3-6311-4bd2-a613-5b21a1df9082",
   "metadata": {
    "language": "sql",
    "name": "create_segment_col_train"
   },
   "outputs": [],
   "source": "ALTER TABLE DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\nADD COLUMN IF NOT EXISTS LOAN_PURPOSE VARCHAR(50);\n\n\nUPDATE DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\nSET LOAN_PURPOSE = CASE\n    WHEN LOAN_PURPOSE_NAME_HOME_IMPROVEMENT = 1 THEN 'HOME_IMPROVEMENT'\n    WHEN LOAN_PURPOSE_NAME_HOME_PURCHASE = 1 THEN 'HOME_PURCHASE'\n    WHEN LOAN_PURPOSE_NAME_REFINANCING = 1 THEN 'REFINANCING'\n    ELSE 'OTHER'\nEND;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8d51f7b-8e3e-4a30-b7c5-606986f668cd",
   "metadata": {
    "language": "sql",
    "name": "view_loan_purpose_data"
   },
   "outputs": [],
   "source": "SELECT LOAN_PURPOSE_NAME_HOME_PURCHASE, LOAN_PURPOSE_NAME_HOME_IMPROVEMENT, LOAN_PURPOSE_NAME_REFINANCING, LOAN_PURPOSE FROM DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}} limit 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6be548-47cb-4a91-92ee-a5f42c41e756",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "create_model_monitor_base",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_BASE_MODEL_MONITOR\nWITH\n    MODEL={{model_name}}\n    VERSION={{base_version_name}}\n    FUNCTION=predict\n    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n    TIMESTAMP_COLUMN=TIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(XGB_BASE_PREDICTION)  \n    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n    ID_COLUMNS=(LOAN_ID)\n    SEGMENT_COLUMNS = ('LOAN_PURPOSE')\n    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n    REFRESH_INTERVAL='12 hours'\n    AGGREGATION_WINDOW='1 day';"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60965976-f17f-42bc-92ae-e43030bba54e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "create_model_monitor_optimized",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_OPTIMIZED_MODEL_MONITOR\nWITH\n    MODEL={{model_name}}\n    VERSION={{optimized_version_name}}\n    FUNCTION=predict\n    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n    TIMESTAMP_COLUMN=TIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(XGB_OPTIMIZED_PREDICTION)  \n    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n    ID_COLUMNS=(LOAN_ID)\n    SEGMENT_COLUMNS = ('LOAN_PURPOSE')\n    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n    REFRESH_INTERVAL='12 hours'\n    AGGREGATION_WINDOW='1 day';"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b0fc2-555d-458b-aa07-7053859539d4",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "generate_model_registry_link"
   },
   "outputs": [],
   "source": [
    "#Click the generated link to view your model in the model regsitry and check out the model monitors!\n",
    "st.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/data/databases/{DB}/schemas/{SCHEMA}/model/{model_name.upper()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fc658-38f4-4c9a-980b-cf40ef61a268",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "compute_prediction_drift"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n",
    "'MORTGAGE_LENDING_BASE_MODEL_MONITOR', -- model monitor to use\n",
    "'DIFFERENCE_OF_MEANS', -- metric for computing drift\n",
    "'XGB_BASE_PREDICTION', -- comlumn to compute drift on\n",
    "'1 DAY',  -- day granularity for drift computation\n",
    "DATEADD(DAY, -90, CURRENT_DATE()), -- end date\n",
    "DATEADD(DAY, -60, CURRENT_DATE()) -- start date\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f8d88-1ebe-4622-89ca-39bce08473d4",
   "metadata": {
    "collapsed": false,
    "name": "SPCS_MD"
   },
   "source": [
    "# SPCS Deployment setup (OPTIONAL)\n",
    "## This is disabled by default but uncommenting the below code cells will allow a user to \n",
    "\n",
    "- ### Create a new compute pool with 3 XL CPU nodes\n",
    "- ### Deploys a service on top of our existing HPO model version\n",
    "- ### Tests out inference on newly created container service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416a4d0-a95f-4702-9a61-26b61706eb11",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "define_spcs_vars"
   },
   "outputs": [],
   "source": "cp_name = \"MORTGAGE_LENDING_INFERENCE_CP\"\nnum_spcs_nodes = '2'\nspcs_instance_family = 'CPU_X64_L'\nservice_name = 'MORTGAGE_LENDING_PREDICTION_SERVICE'\n\ncurrent_database = session.get_current_database().replace('\"', '')\ncurrent_schema = session.get_current_schema().replace('\"', '')\nextended_service_name = f'{current_database}.{current_schema}.{service_name}'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f6702-8fb2-4aac-9e54-a8673c064074",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "setup_compute_pool"
   },
   "outputs": [],
   "source": "session.sql(f\"alter compute pool if exists {cp_name} stop all\").collect()\nsession.sql(f\"drop compute pool if exists {cp_name}\").collect()\nsession.sql(f\"create compute pool {cp_name} min_nodes={num_spcs_nodes} max_nodes={num_spcs_nodes} instance_family={spcs_instance_family} auto_resume=True auto_suspend_secs=300\").collect()\nsession.sql(f\"describe compute pool {cp_name}\").show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47725b-e9e7-4f93-bdea-9db09794bd95",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "spcs_deploy_service"
   },
   "outputs": [],
   "source": "#note this may take up to 5 minutes to run\n\nmv_opt.create_service(\n    service_name=extended_service_name,\n    service_compute_pool=cp_name,\n    ingress_enabled=True,\n    max_instances=int(num_spcs_nodes)\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4f6d4-b16b-4448-bcf3-4f128ccfbe43",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "see_model_versions_with_services"
   },
   "outputs": [],
   "source": "model_registry.get_model(f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\").show_versions()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb9b1a-0741-4e9d-aaf4-2da26c44ffbd",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "run_SPCS_inference"
   },
   "outputs": [],
   "source": "mv_container = model_registry.get_model(f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\").default\nmv_container.run(test, function_name = \"predict\", service_name = \"MORTGAGE_LENDING_PREDICTION_SERVICE\").rename('\"output_feature_0\"', 'XGB_PREDICTION')"
  },
  {
   "cell_type": "code",
   "id": "ae787271-b9b6-4e4d-b8a3-2234d376f568",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "\nendpoint = session.sql(\"SHOW ENDPOINTS IN SERVICE E2E_SNOW_MLOPS_DB.MLOPS_SCHEMA.MORTGAGE_LENDING_PREDICTION_SERVICE\").collect()\npd.DataFrame(endpoint)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd5c1c3e-e13f-4ec7-983d-421637e4fc8f",
   "metadata": {
    "language": "sql",
    "name": "token_gen"
   },
   "outputs": [],
   "source": "alter user admin add programmatic access token t2 mins_to_bypass_network_policy_requirement=1000;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab6c3766-dba9-4d26-bb0b-2632bdb5b64c",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "\nimport requests\n\n# Get Programmatic Access Token\n#pat = open('pat-token-secret.txt','r').read()\ndf_token = token_gen.to_df()\npat = df_token.collect()[0][\"token_secret\"] \nURL = f\"https://{endpoint[0]['ingress_url']}/predict\"\nheaders = {\"Authorization\": f'Snowflake Token=\"{pat}\"'}\n\nrow_dict = {\n    \"LOAN_PURPOSE_NAME_HOME_IMPROVEMENT\": 0,\n    \"LOAN_PURPOSE_NAME_HOME_PURCHASE\": 1,\n    \"LOAN_PURPOSE_NAME_REFINANCING\": 0,\n    \"MONTH\": 1,\n    \"DAY_OF_YEAR\": 27,\n    \"DOTW\": 1,\n    \"LOAN_AMOUNT\": float(238000),\n    \"INCOME\": float(97000),\n    \"INCOME_LOAN_RATIO\": float(0.4075999855995178),\n    \"MEAN_COUNTY_INCOME\": float(168684.75),\n    \"HIGH_INCOME_FLAG\": 0,\n    \"AVG_THIRTY_DAY_LOAN_AMOUNT\": float(315169.90625),\n}\n\npayload_data = {\n    \"data\": [\n        [0, row_dict]\n    ]\n}\n\nst.header(\"Input Data:\")\nst.json(payload_data)\n\nst.write(\"---\")\nst.header(\"Output:\")\n\nr = requests.post(URL, json=payload_data, headers=headers)\n\nst.write(\"Status code:\", r.status_code)\nst.write(\"Content-Type:\", r.headers.get(\"Content-Type\"))\n\ntry:\n    resp_json = r.json()\n    st.subheader(\"Parsed JSON response:\")\n    st.json(resp_json)\nexcept ValueError:\n    st.error(\"Response is not valid JSON\")\n    st.text(r.text)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35388bca-f70f-47db-a3ef-3558dda91502",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "stop_compute_pool"
   },
   "outputs": [],
   "source": [
    "#Stop the service to save costs\n",
    "# session.sql(f\"alter compute pool if exists {cp_name} stop all\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000036",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "name": "conclusion",
    "resultHeight": 202,
    "tags": []
   },
   "source": [
    "## Conclusion \n",
    "\n",
    "#### 🛠️ Snowflake Feature Store tracks feature definitions and maintains lineage of sources and destinations 🛠️\n",
    "#### 🚀 Snowflake Model Registry gives users a secure and flexible framework to log models, tag candidates for production, and run inference and explainability jobs 🚀\n",
    "#### 📈 ML observability in Snowflake allows users to montior model performance over time and detect model, feature, and concept drift 📈\n",
    "#### 🔮 All models logged in the Model Registry can be accessed for inference, explainability, lineage tracking, visibility and more 🔮\n"
   ]
  }
 ]
}